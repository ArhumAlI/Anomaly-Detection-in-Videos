{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "UCSD_Gans_CONVLSTM_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ohmYn8xAZC3",
        "colab_type": "text"
      },
      "source": [
        "# **Necessary Imports**\n",
        "# Run each cell by pressing shift+enter keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RQKeRzZcwU0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras_layer_normalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "76FZZv_GwUzn",
        "colab_type": "code",
        "outputId": "7c9c05bd-e748-41c4-bc0e-3fd74b5d19c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "\n",
        "\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras import losses\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import keras.backend as K\n",
        "import scipy\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "\n",
        "from skimage.util import random_noise\n",
        "from PIL import Image\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1aloLzXAZDJ",
        "colab_type": "text"
      },
      "source": [
        "# **Run the cell and mount your google drive by following the generated link**\n",
        "\n",
        "# Copy the code and paste in the section below, and then press enter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nnDgqe2wjxz",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLEHiVVAZDQ",
        "colab_type": "text"
      },
      "source": [
        "# **The following cell will copy the training data from your google drive to colab **\n",
        "# For this to work you will need to upload the training data as Training.zip under a new folder \"UCSD\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LJPA3LnwtMr",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Train\n",
        "!unzip -q \"/gdrive/My Drive/UCSD/Training.zip\" -d Train\n",
        "Dataset_Path =\"Train/*/*\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKFKy3oDp2zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dataset_Path =\"Train/*/*\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07CRO98cAZDd",
        "colab_type": "text"
      },
      "source": [
        "# Training Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxKadEjCSKcP",
        "colab_type": "text"
      },
      "source": [
        "# Get Frames as 10 frames per input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-sEQ2QlJwUz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_data():\n",
        "    \n",
        "    files = sorted(glob.glob(Dataset_Path))\n",
        "    \n",
        "    input_shape = (256,256)\n",
        "\n",
        "    n = 10\n",
        "    data = np.zeros((int(len(files)/n), n, 256, 256, 1))\n",
        "    i = 0\n",
        "    idx = 0\n",
        "\n",
        "    # Loop over all the Training Videos\n",
        "    for filename in files:\n",
        "        # Open image in grayscale\n",
        "        im = Image.open(filename).convert('L')\n",
        "\n",
        "        # Resize all frames to 256x256 dimensions\n",
        "        im = im.resize((input_shape[0],input_shape[1]))\n",
        "\n",
        "        # Normalize frames to range in 0 to 1. Is computionally suitable.        \n",
        "        img = np.array(im, dtype=np.float32)/255.0\n",
        "\n",
        "        # frames get appended in the form [total_frames, 10, 256, 256, 1]\n",
        "        data[idx,i,:,:,:] = img.reshape(input_shape[0],input_shape[1], 1)\n",
        "        i = i + 1\n",
        "        if i >= n:\n",
        "          idx = idx + 1\n",
        "          i = 0\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwWt1l5AZDk",
        "colab_type": "text"
      },
      "source": [
        "# The function below adds random noise to each frame of each video. This adds some flexibility in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9zHWWXn3wUz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_noisy_data(data):\n",
        "    noisy = []\n",
        "    sigma = 0.155\n",
        "\n",
        "    for frame in data:\n",
        "        try:\n",
        "            # Add random noise to each frame. \n",
        "            noisy_frame = random_noise(frame, var=sigma ** 2)\n",
        "            noisy.append(noisy_frame)\n",
        "        except ValueError:  \n",
        "            print(error)\n",
        "            pass\n",
        "    return np.array(noisy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g_X2IwmAZDq",
        "colab_type": "text"
      },
      "source": [
        "# *The Training class including all the network architechture *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5Z2VUdUfwU0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Training_Model():\n",
        "    def __init__(self):\n",
        "\n",
        "        # learning rate\n",
        "        self.alpha = 0.08\n",
        "\n",
        "        self.input_height = 256\n",
        "        self.input_width = 256\n",
        "        self.output_height =256 \n",
        "        self.output_width = 256\n",
        "        \n",
        "        # 1 for grayscale\n",
        "        self.channels = 1\n",
        "        \n",
        "        # get the training data\n",
        "        self.training_data = get_training_data()\n",
        "        print(\"Training Data\", self.training_data.shape)\n",
        "        \n",
        "        # create the adversarial model\n",
        "        self.create_networks()\n",
        "    \n",
        "    def create_networks(self):\n",
        "        # this would be the shape of the sequence. i.e. [10, 256, 256, 1]\n",
        "        frame_dims = [10, self.input_height, self.input_width, self.channels]\n",
        "        \n",
        "        # Selecting an optimizer which helps trainsa and learn the optimal paramaters \n",
        "        optimizer = RMSprop(lr=0.002, clipvalue=1.0, decay=1e-8)\n",
        "        \n",
        "        # Create the Discriminator network which takes original frames as input. This function (create_discriminator defined below) \n",
        "        # descibes the architecjture of the discriminator model\n",
        "        self.discriminator = self.create_discriminator(frame_dims)\n",
        "\n",
        "\n",
        "        # Discriminator model is not trained for the combined network only the generator is trained. Discriminator only differentiates between inputs like a\n",
        "        # comparison function where euclidean distance of the two frames separates them.\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # Model trained to discriminate real images from fake. Compiled model with a binary crossentropy loss since this\n",
        "        # is the output is binary (0/1). It would either be real or fake. \n",
        "        self.discriminator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "        # Similarly creating the Generator network. Function create_generator is defined within \n",
        "        #  this class as a separate which defines the architechture of the Generator model. \n",
        "        self.generator = self.create_generator(frame_dims)\n",
        "        self.generator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "        \n",
        "        \n",
        "        print('\\nGenerator Model')\n",
        "        \n",
        "        # summary describes the no. of paramaters required to train each layer in the network. \n",
        "        self.generator.summary()\n",
        "\n",
        "\n",
        "        inp = Input(shape=frame_dims)\n",
        "\n",
        "        reconstructed_frames = self.generator(inp)\n",
        "\n",
        "        # This is arbitrary validation for the discriminator to learn about the Generator model.\n",
        "        validate = self.discriminator(reconstructed_frames)\n",
        "        \n",
        "        # The Adversarial Model to train the Generator to minimize reconstruction loss and trick Discriminator\n",
        "        # into beleiving generated images as real ones.\n",
        "        self.adversarial_model = Model(inp, [reconstructed_frames, validate])\n",
        "        \n",
        "        \n",
        "        # Setup the adversarial model here with two losses one for each network.\n",
        "        self.adversarial_model.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n",
        "            loss_weights=[self.alpha, 1],\n",
        "            optimizer=optimizer)\n",
        "\n",
        "        print('\\nDiscriminator')\n",
        "        self.discriminator.summary()\n",
        "\n",
        "        print('\\nCombined Adversarial Model')\n",
        "        self.adversarial_model.summary()\n",
        "    \n",
        "    \n",
        "\n",
        "    def create_discriminator(self, input_shape):\n",
        "        \n",
        "        # Instantiate D Network\n",
        "        frames = Input(shape=input_shape)\n",
        "        \n",
        "        # Feature Extraction through convolution operations. \n",
        "        x = TimeDistributed(Conv2D(filters=16, kernel_size = 5, strides=2, padding='same'))(frames)\n",
        "        # Normalize in the range -1 to max\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        x = TimeDistributed(Conv2D(filters=32, kernel_size = 5, strides=2, padding='same'))(x)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        x = TimeDistributed(Conv2D(filters=64, kernel_size = 5, strides=2, padding='same'))(x)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        x = TimeDistributed(Conv2D(filters=128, kernel_size = 5, strides=2, padding='same'))(x)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = LeakyReLU()(x)\n",
        "        \n",
        "        \n",
        "        # Flatten converts the 2D frame into a single dimension vector from where a final score is computed\n",
        "        # using the sigmoid function which returns in the range of 0 to 1.\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        return Model(frames, x)\n",
        "    \n",
        "     \n",
        "\n",
        "    def create_generator(self, input_shape):\n",
        "        # Videos are sequential hence we need a sequential model\n",
        "        encoder = Sequential()\n",
        "        \n",
        "        \n",
        "        ####################################### ENCODER PART #################################################### \n",
        "        # Encodes daata\n",
        "        generator = self.add_encoder(encoder)\n",
        "        \n",
        "        ####################################### ENCODING DONE ###################################################\n",
        "        \n",
        "        ############################### TEMPORAL FEATURE EXTRACTION STARTS ######################################\n",
        "        \n",
        "        # Conv-lstm extract the temporal features. A conv operartion with 64 masks but no multiplication takes place.\n",
        "        # Instead the model memorizes the repetetive patterns.\n",
        "        generator.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "        generator.add(LayerNormalization())\n",
        "        generator.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "        generator.add(LayerNormalization())\n",
        "        generator.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "        generator.add(LayerNormalization())\n",
        "        \n",
        "        ############################### TEMPORAL FEATURE EXTRACTION ENDS ########################################\n",
        "        \n",
        "        \n",
        "        ####################################### DECODING STARTS ###################################################\n",
        "        \n",
        "        # Upsample the encoded data back to original data\n",
        "        decoded = self.deconv(generator)\n",
        "\n",
        "        \n",
        "        ####################################### DECODING DONE ###################################################\n",
        "        \n",
        "        return decoded\n",
        "\n",
        "\n",
        "    def add_encoder(self, model):\n",
        "        # The first layer where a convolution mask of size 11x11 spans each of the ten frames with a stride of 4. \n",
        "        # The 10 256x256 frames are reduced to 64x64. Basis expansion takes the 1 channel frame into 128 subframes.\n",
        "        model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "        \n",
        "        # Normalize the above layer's output to feed into next layer.    \n",
        "        model.add(LayerNormalization())\n",
        "        \n",
        "        # Similar to first layer, conv layer extracts features from frames reducing further to 32x32  \n",
        "        model.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "        model.add(LayerNormalization())\n",
        "\n",
        "        return model\n",
        "\n",
        "    # Upsample the encoded data back to original data \n",
        "    def deconv(self, model):\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "        model.add(LayerNormalization())\n",
        "        model.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "        model.add(LayerNormalization())\n",
        "\n",
        "        # 10 frames generated output generated of the same shape as the input data. \n",
        "        model.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "      \n",
        "        return model\n",
        "        \n",
        "\n",
        "    def train(self, epochs, batch_size):\n",
        "\n",
        "        # Record Generator network G's reconstruction training losses.\n",
        "        plot_g_losses = []\n",
        "        plot_g_recontruction_losses = []\n",
        "\n",
        "        sample_files = self.training_data    \n",
        "    \n",
        "        noisy_data = get_noisy_data(self.training_data)\n",
        "        print(\"noisy_data.shape\",noisy_data.shape)\n",
        "        \n",
        "        # Adversarial ground truths\n",
        "        ones = np.ones(batch_size)\n",
        "        zeros = np.zeros(batch_size)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print('Epoch ({}/{})-------------------------------------------------'.format(epoch,epochs))\n",
        "            \n",
        "            # Batches help reduce memory constraint. Number of batches computed by total number of target data / batch size.\n",
        "            batches = len(self.training_data) // batch_size\n",
        "            \n",
        "            for id in range(batches):\n",
        "\n",
        "                # Get a batch of original and noisy framesframes .\n",
        "                batch = self.training_data[id * batch_size:(id + 1) * batch_size]\n",
        "                noisy_batch = noisy_data[id * batch_size:(id + 1) * batch_size]\n",
        "                \n",
        "                # Turn batch data to float32 type.\n",
        "                frames_with_noise = np.array(noisy_batch).astype(np.float32)\n",
        "                original_frames = np.array(batch).astype(np.float32)\n",
        "\n",
        "                # generate fake frames\n",
        "                batch_fake_frames = self.generator.predict(frames_with_noise)\n",
        "                \n",
        "                # Update Discriminator to minimize original frame inputs ->D-> ones, noisy z->G->D->zeros loss.\n",
        "                discriminator_loss_original_data = self.discriminator.train_on_batch(original_frames, ones)\n",
        "                discriminator_loss_fake_data = self.discriminator.train_on_batch(batch_fake_frames, zeros)\n",
        "\n",
        "                # Update R network twice, minimize noisy z->R->D->ones and reconstruction loss.\n",
        "                self.adversarial_model.train_on_batch(frames_with_noise, [original_frames, ones])\n",
        "                gen_loss = self.adversarial_model.train_on_batch(frames_with_noise, [original_frames, ones])    \n",
        "                \n",
        "                plot_g_losses.append(epoch+id/batches)\n",
        "                plot_g_recontruction_losses.append(gen_loss[1])\n",
        "\n",
        "                msg = 'Epoch:[{0}]-[{1}/{2}] --> d_loss: {3:>0.3f}, gen_loss:{4:>0.3f}'.format(epoch, id, batches, discriminator_loss_original_data+discriminator_loss_fake_data, gen_loss[0])\n",
        "                print(msg)\n",
        "\n",
        "        # Export the Generator/R network reconstruction losses as a plot.\n",
        "        plt.title('Generator network reconstruction loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('training loss')\n",
        "        plt.grid()\n",
        "        plt.plot(plot_epochs,plot_g_recontruction_losses)\n",
        "        self.adversarial_model.save(\"Model_PED2.hdf5\")\n",
        "        # plt.savefig('plot_g_recon_losses.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vNxcBdDAZDw",
        "colab_type": "text"
      },
      "source": [
        "# Run this cell to instantiate the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "daEVKw2-wU0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Training_Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVg_VOrLAZD1",
        "colab_type": "text"
      },
      "source": [
        "# Run this to let the training begin. It would take a lot of time to train.\n",
        "# Batch size is the number of samples to be trained at once and the number of times you want the code to run as epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BGb-wvxDwU0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train(epochs=200, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPQwCf46qI1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}